automatic dialogue response evaluator has been proposed as an alternative
automatic dialogue response evaluator has been proposed as an alternative
exploit the power of semi-supervised training and pretrained (masked) language models
experimental results demonstrate that the proposed
experimental results demonstrate that the proposed
we open-source the code and data in https://github.com/
dialogue research experimental result automatic dialogue response evaluator
particularly for open-domain dialogues dialogue research experimental result automatic dialogue response evaluator
although human evaluation provides the most accurate assessment
learns to predict a human-like score automatic dialogue response evaluator

experimental results demonstrate that the proposed evaluator achieves a strong correlation 
to diverse responses and corpora//
automated metrics correlate poorly with human judgement they are not robust
automated metrics correlate poorly with human judgement they are not robust human evaluation slow and expensive.
automated metrics correlate poorly with human judgement they are not robust human evaluation slow and expensive.
automated metrics correlate poorly with human judgement they are not robust human evaluation slow and expensive.
automated metrics correlate poorly with human judgement they are not robust human evaluation slow and expensive.
automated metrics correlate poorly with human judgement they are not robust human evaluation slow and expensive.
automated metrics correlate poorly with human judgement they are not robust human evaluation slow and expensive.
moderate correlations correlate poorly with human judgement human evaluation slow and expensive
moderate correlations correlate poorly with human judgement human evaluation slow and expensive
lacks robustness under adversarial attack poorly with human judgement
lacks robustness under adversarial attack poorly with human judgement
lacks robustness under adversarial attack poorly with human judgement
lacks robustness of response under adversarial attack poorly with human judgement
reference-dependent metrics lacks robustness under adversarial attack poorly with human judgement
reference-dependent metrics lacks robustness under adversarial attack poorly with human judgement
generalizes to new dialogues unseen during training reference-dependent metrics lacks robustness under adversarial attack poorly with human judgement
reference-dependent metrics lacks robustness under adversarial attack poorly with human judgement
reference-dependent metrics lacks robustness under adversarial attack poorly with human judgement
reference-dependent metrics lacks robustness under adversarial attack poorly with human judgement
reference-dependent metrics lacks robustness under adversarial attack poorly with human judgement
reference-dependent metrics lacks robustness under adversarial attack poorly with human judgement
reference-dependent metrics lacks robustness under adversarial attack poorly with human judgement
obtain better text representations reference-dependent metrics lacks robustness under adversarial attack poorly with human judgement
evaluators correlation reference-dependent metrics lacks robustness under adversarial attack poorly with human judgement
evaluatorsresponse appropriateness correlation reference-dependent metrics lacks robustness under adversarial attack poorly with human judgement
evaluatorsresponse appropriateness correlation reference-dependent metrics lacks robustness under adversarial attack poorly with human judgement
evaluatorsresponse appropriateness correlation reference-dependent metrics lacks robustness under adversarial attack poorly with human judgement
next sentence prediction evaluatorsresponse appropriateness reference-dependent metrics lacks robustness under adversarial attack poorly with human judgement
next sentence prediction evaluatorsresponse appropriateness reference-dependent metrics lacks robustness under adversarial attack poorly with human judgement
adem and ruber shortcomings next sentence prediction evaluatorsresponse appropriateness reference-dependent metrics lacks robustness under adversarial attack poorly with human judgement
next sentence prediction is to predict whether a sentence is a true continuation given a preceding contex adem and ruber shortcomings next sentence prediction evaluatorsresponse appropriateness reference-dependent metrics lacks robustness under adversarial attack poorly with human judgement
evaluation language understanding generation next sentence prediction is to predict whether a sentence is a true continuation given a preceding contex adem and ruber shortcomings next sentence prediction evaluatorsresponse appropriateness reference-dependent metrics lacks robustness under adversarial attack poorly with human judgement
next sentence prediction response evaluation reference-dependent metrics lacks robustness
next sentence prediction response evaluation reference-dependent metrics lacks robustness
next sentence prediction response evaluation reference-dependent metrics lacks robustness
next sentence prediction response evaluation reference-dependent metrics lacks robustness
next sentence prediction response evaluation reference-dependent metrics lacks robustness
next sentence prediction response evaluation reference-dependent metrics lacks robustness
next sentence prediction response evaluation reference-dependent metrics lacks robustness
next sentence prediction response evaluation reference-dependent metrics lacks robustness